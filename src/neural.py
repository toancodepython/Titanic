import os
import mlflow
import streamlit as st
import tensorflow as tf
import numpy as np
import cv2
from streamlit_drawable_canvas import st_canvas
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.datasets import mnist
from sklearn.model_selection import train_test_split
def log_experiment(model_name):
    try:
        DAGSHUB_USERNAME = "toancodepython"  # Thay b·∫±ng username c·ªßa b·∫°n
        DAGSHUB_REPO_NAME = "ml-flow"
        DAGSHUB_TOKEN = "a6e8c1682e60df503248dcf37f42ca15ceaee13a"  # Thay b·∫±ng Access Token c·ªßa b·∫°n
        mlflow.set_tracking_uri("https://dagshub.com/toancodepython/ml-flow.mlflow")
        # Thi·∫øt l·∫≠p authentication b·∫±ng Access Token
        os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
        os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

        experiment_name = "Neural Network"
        experiment = next((exp for exp in mlflow.search_experiments() if exp.name == experiment_name), None)
        if experiment:
            experiment_id = experiment.experiment_id
            print(f"Experiment ID: {experiment_id}")
            mlflow.set_experiment(experiment_name)
            with mlflow.start_run(run_name = model_name) as run:
                print('Logging...')
                mlflow.log_param("num_neurons", st.session_state.number)
                mlflow.log_param("num_hidden_layers", st.session_state.hidden_layer)
                mlflow.log_param("epochs", st.session_state.epoch)
                mlflow.log_param("optimizer", st.session_state.optimizer)
                mlflow.log_param("loss_function", st.session_state.loss)
                mlflow.log_metric("Accuracy", st.session_state.accuracy)
                st.success(f"‚úÖ M√¥ h√¨nh ƒë∆∞·ª£c log v√†o th√≠ nghi·ªám: {experiment_name}")
        else:
            # N·∫øu th√≠ nghi·ªám ch∆∞a t·ªìn t·∫°i, t·∫°o m·ªõi
            experiment_id = mlflow.create_experiment(experiment_name)
        print("Active Run:", mlflow.active_run())
    except Exception as e:
        st.warning("Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi MLflow ho·∫∑c DagsHub. Vui l√≤ng ki·ªÉm tra c√†i ƒë·∫∑t.")
# X√¢y d·ª±ng m√¥ h√¨nh
def create_model(num_hidden_layers, num_neurons,optimizer, loss_function):
    model = Sequential([Flatten(input_shape=(28, 28))])
    for _ in range(num_hidden_layers):
        model.add(Dense(num_neurons, activation='relu'))
    model.add(Dense(10, activation='softmax'))
    model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])
    return model

def display():
    # Load MNIST dataset
    (x, y), (_, _) = mnist.load_data()
    x = x / 255.0  # Chu·∫©n h√≥a d·ªØ li·ªáu

    # Streamlit UI
    st.title("Nh·∫≠n di·ªán ch·ªØ s·ªë MNIST")
    st.header("Tham s·ªë m√¥ h√¨nh")

    # L·ª±a ch·ªçn s·ªë l∆∞·ª£ng m·∫´u d·ªØ li·ªáu
    st.write("**S·ªë l∆∞·ª£ng m·∫´u**: S·ªë l∆∞·ª£ng ·∫£nh ƒë∆∞·ª£c s·ª≠ d·ª•ng cho vi·ªác hu·∫•n luy·ªán v√† ki·ªÉm tra.")
    num_samples = int(st.number_input("S·ªë l∆∞·ª£ng m·∫´u", 1000, 70000, 70000, step=1000))

    st.write("**T·ªâ l·ªá t·∫≠p hu·∫•n luy·ªán**: Ph·∫ßn trƒÉm d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.")
    train_ratio = float(st.number_input("T·ªâ l·ªá t·∫≠p hu·∫•n luy·ªán", 0.5, 0.9, 0.8, step=0.05))

    st.write("**T·ªâ l·ªá t·∫≠p validation**: Ph·∫ßn trƒÉm d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh trong qu√° tr√¨nh hu·∫•n luy·ªán.")
    val_ratio = float(st.number_input("T·ªâ l·ªá t·∫≠p validation", 0.05, 0.3, 0.1, step=0.05))
    test_ratio = 1 - train_ratio - val_ratio

    # Chia t·∫≠p d·ªØ li·ªáu
    x_train, x_temp, y_train, y_temp = train_test_split(x[:num_samples], y[:num_samples], train_size=train_ratio, stratify=y[:num_samples])
    x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=test_ratio/(test_ratio + val_ratio), stratify=y_temp)

    st.write(f"S·ªë l∆∞·ª£ng m·∫´u hu·∫•n luy·ªán: {len(x_train)}, m·∫´u validation: {len(x_val)}, m·∫´u ki·ªÉm tra: {len(x_test)}")

    # Tham s·ªë m√¥ h√¨nh
    st.write("**S·ªë neuron m·ªói l·ªõp**: S·ªë l∆∞·ª£ng neuron trong m·ªói l·ªõp ·∫©n c·ªßa m√¥ h√¨nh.")
    num_neurons = int(st.number_input("S·ªë neuron m·ªói l·ªõp", 32, 512, 128, step=32))
    st.session_state.number = num_neurons
    st.write("**S·ªë l·ªõp ·∫©n**: S·ªë l∆∞·ª£ng l·ªõp k·∫øt n·ªëi trong m·∫°ng neuron.")
    num_hidden_layers = int(st.number_input("S·ªë l·ªõp ·∫©n", 1, 5, 2))
    st.session_state.hidden_layer = num_hidden_layers
    st.write("**S·ªë epochs**: S·ªë l·∫ßn m√¥ h√¨nh duy·ªát qua to√†n b·ªô t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán.")
    epochs = int(st.number_input("S·ªë epochs", 5, 50, 10, step=5))
    st.session_state.epoch = epochs
    st.write("**Optimizer**: Thu·∫≠t to√°n t·ªëi ∆∞u h√≥a gi√∫p gi·∫£m thi·ªÉu h√†m m·∫•t m√°t.")
    optimizer = st.selectbox("Optimizer", ["adam", "sgd", "rmsprop"])
    st.session_state.optimizer = optimizer
    st.write("**H√†m m·∫•t m√°t**: H√†m ƒë√°nh gi√° m·ª©c ƒë·ªô l·ªói c·ªßa m√¥ h√¨nh.")
    loss_function = st.selectbox("H√†m m·∫•t m√°t", ["sparse_categorical_crossentropy", "categorical_crossentropy"])
    st.session_state.loss = loss_function
    if "accuracy" not in st.session_state:
        st.session_state.accuracy = 0
    if "number" not in st.session_state:
        st.session_state.number = 0
    if "train_sample" not in st.session_state:
        st.session_state.train_sample = 0
    if "test_sample" not in st.session_state:
        st.session_state.test_sample = 0
    if "val_sample" not in st.session_state:
        st.session_state.val_sample = 0
    if "hidden_layer" not in st.session_state:
        st.session_state.hidden_layer = 0
    if "epoch" not in st.session_state:
        st.session_state.epoch = 0
    if "optimizer" not in st.session_state:
        st.session_state.optimizer = 0
    if "loss" not in st.session_state:
        st.session_state.loss = 0
    if "log_success" not in st.session_state:
        st.session_state.log_success = False


    # Hu·∫•n luy·ªán m√¥ h√¨nh
    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
        model = create_model(loss_function=loss_function, num_hidden_layers=num_hidden_layers, num_neurons=num_neurons, optimizer=optimizer)
        with st.spinner("ƒêang hu·∫•n luy·ªán..."):
            history = model.fit(x_train, y_train, epochs=epochs, batch_size=5, verbose=0)
            st.session_state.model = model
            st.session_state.accuracy = history.history['val_accuracy'][-1]  # L∆∞u ƒë·ªô ch√≠nh x√°c
        st.success("Hu·∫•n luy·ªán th√†nh c√¥ng!")
        st.write(f"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p validation: {st.session_state.accuracy:.4f}")
        
    st.subheader("V·∫Ω m·ªôt ch·ªØ s·ªë (0-9)")
    canvas = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=200,
        width=200,
        drawing_mode="freedraw",
        key="canvas",
    )
    # D·ª± ƒëo√°n ch·ªØ s·ªë
    if 'model' in st.session_state:
    
        if canvas.image_data is not None and st.button("D·ª± ƒëo√°n"):
            image = cv2.cvtColor(canvas.image_data.astype(np.uint8), cv2.COLOR_RGBA2GRAY)
            image = cv2.resize(image, (28, 28))
            image = image / 255.0
            image = image.reshape(1, 28, 28)
            pred = st.session_state.model.predict(image)
            predicted_digit = np.argmax(pred)
            confidence = np.max(pred)
            st.write(f"Ch·ªØ s·ªë d·ª± ƒëo√°n: {predicted_digit}")
            st.write(f"ƒê·ªô tin c·∫≠y: {confidence:.4f}")

        model_name = st.text_input("üè∑Ô∏è Nh·∫≠p t√™n m√¥ h√¨nh", key = "0")
        if st.button("Log Experiment Clustering", key = "btn_4"):
            log_experiment(model_name) 

        # Hi·ªÉn th·ªã tr·∫°ng th√°i log th√†nh c√¥ng
        if st.session_state.log_success:
            st.success("üöÄ Experiment ƒë√£ ƒë∆∞·ª£c log th√†nh c√¥ng!")